from bs4 import BeautifulSoup

import requests
import time
import json

url = 'http://bj.58.com/pbdn/?PGTID=0d100000-0000-1121-f41b-137aeef068b7&ClickID=6'
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.48 Safari/537.36',

}

def get_info(url):
    wb_data = requests.get(url, headers=headers)
    time.sleep(2)
    soup = BeautifulSoup(wb_data.text, 'lxml')
    title = soup.select('h1')[0].text
    date = soup.select('.time')[0].text
    price = soup.select('.price')[0].text
    cate = soup.select('span.crb_i')[1].text
    business_type = '个人' if soup.select('ul.userinfo') else '商家'
    areas = soup.select('span.c_25d')
    if areas == []:
        area = '北京'
    else:
        area = ' '.join(areas[0].get_text().split())
        
    data = {'商品标题':title,'发帖时间':date,'价格':price,'卖家类型':business_type,'区域':area,'类目':cate}

    print(data)

web = requests.get(url,headers=headers)
soup = BeautifulSoup(web.text,'lxml')
crawl_lists = soup.select('tr > td.img > a')
for crawl_list in crawl_lists:
    info_url = crawl_list.get('href')
    get_info(info_url)
